{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True\n",
    "import re\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import parallel_bulk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import requests\n",
    "from time import time\n",
    "import time\n",
    "\n",
    "import base64\n",
    "import xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200, 'timeout': 360, 'maxsize': 25}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acknowledged': True, 'shards_acknowledged': True, 'index': 'myandex'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_by_id = {}\n",
    "es.indices.delete(index='myandex')\n",
    "es.indices.create(index='myandex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processFile(i):\n",
    "    prefix = '../hw_1/byweb_for_course/byweb.'\n",
    "    suffix = '.xml'\n",
    "    filename = prefix + str(i) + suffix\n",
    "    with open(filename, 'rb') as f:\n",
    "        decoded = f.read().decode('cp1251')\n",
    "        xmldict = xmltodict.parse(decoded)\n",
    "        for doc in tqdm(xmldict['romip:dataset']['document']):\n",
    "            try:\n",
    "                docID = doc['docID']\n",
    "                documents_by_id[docID] = {}\n",
    "                url = base64.b64decode(doc['docURL']).decode('cp1251')\n",
    "                content = base64.b64decode(doc['content']['#text']).decode('cp1251')\n",
    "                documents_by_id[docID]['url'] = url\n",
    "                documents_by_id[docID]['content'] = content\n",
    "            except Exception as e:\n",
    "                print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71a8613f5f54657a613b69287aa436a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0de2bde94a4656954fd704fcdc0fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15257c5018cc46aea10fc0e0f3a0f8b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0684ec80e7f94775a9611d872a3b77e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694de9db55ec460b8ab6abb98fd71143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40086f048c454bf088b8aa8e6dccc36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15112efd3f8947c099cc6b1f6bcf8099",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec3f60af40d444e0bf46583aababe036",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c4c4e2b16e45608504ecdf61369865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e772b8e5993848c2bfcbeee31b75043c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=20000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    processFile(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_final = {\n",
    "    'mappings': {\n",
    "        'properties': {\n",
    "            'url': {\n",
    "                'type': 'text'\n",
    "            },\n",
    "            'content': {\n",
    "                'type': 'text'\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"settings\": {\n",
    "    \"analysis\": {\n",
    "      \"analyzer\": {\n",
    "        \"my_custom_analyzer\": {\n",
    "          \"type\":      \"custom\", \n",
    "          \"tokenizer\": \"standard\",\n",
    "          \"char_filter\": [\n",
    "            \"html_strip\",\n",
    "            \"yont\"\n",
    "          ],\n",
    "          \"filter\": [\n",
    "            \"lowercase\",\n",
    "            \"asciifolding\",\n",
    "            \"russian_snow\",\n",
    "            \"english_snow\"\n",
    "          ]\n",
    "        }\n",
    "      },\n",
    "        'char_filter': {\n",
    "                'yont': {\n",
    "                    'type': 'mapping',\n",
    "                    'mappings': [\n",
    "                        'ё => е',\n",
    "                        'Ё => Е'\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "    'filter': {\n",
    "            'stop_words': {\n",
    "                'type': 'stop',\n",
    "                'stopwords': [\n",
    "                ]\n",
    "            },\n",
    "            'russian_snow': {\n",
    "                'type': 'snowball',\n",
    "                'language': 'russian'\n",
    "            },\n",
    "            'english_snow': {\n",
    "                'type': 'snowball',\n",
    "                'language': 'english'\n",
    "            }\n",
    "     }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreate_index():\n",
    "    es.indices.delete(index='myandex')\n",
    "    es.indices.create(index='myandex', body=settings_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "recreate_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_analyzer(analyzer, text):\n",
    "    body = analyzer\n",
    "    body['text'] = text\n",
    "    \n",
    "    tokens = es.indices.analyze(index='myandex', body=body)['tokens']\n",
    "    tokens = [token_info['token'] for token_info in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bla', 'bla', 'русск', 'countabl', 'текст', 'ешкин', 'кот']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = {\n",
    "    'analyzer': 'my_custom_analyzer'\n",
    "}\n",
    "\n",
    "check_analyzer(analyzer, '<meta http-equiv=\"Content-Type\" content=\"text/html; charset=windows-1251\"> bla bla русский countable текст Ёшкин кот')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_es_action(index, doc_id, document):\n",
    "    return {\n",
    "        '_index': index,\n",
    "        '_id': doc_id,\n",
    "        '_source': document\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def es_actions_generator():\n",
    "    for doc_id, doc in tqdm(documents_by_id.items()):\n",
    "        yield create_es_action('myandex', doc_id, doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea479fbf1d7c4125b22b3691ce09c5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time on index creation: 00:56:13.12\n",
      "In seconds: 3373.236542701721\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "for ok, result in parallel_bulk(es, es_actions_generator(), queue_size=4, thread_count=4, chunk_size=1000):\n",
    "    if not ok:\n",
    "        print(result)\n",
    "end = time.time()\n",
    "print(f\"Time on index creation: {time.strftime('%H:%M:%S.%l', time.gmtime(end - start))}\")\n",
    "print(f\"In seconds: {end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, *args):\n",
    "    pretty_print_result(es.search(index='myandex', body=query, size=20), args)\n",
    "    # note that size set to 20 just because default value is 10 and we know that we have 12 docs and 10 < 12 < 20\n",
    "\n",
    "def raw_search(query):\n",
    "    search_result = es.search(index='myandex', body=query, size=20)['hits']\n",
    "    return [(hit['_id'], hit['_score']) for hit in search_result['hits']]\n",
    "    \n",
    "def pretty_print_result(search_result, fields=[]):\n",
    "    # fields is a list of fields names which we want to be printed\n",
    "    res = search_result['hits']\n",
    "    print(f'Total documents: {res[\"total\"][\"value\"]}')\n",
    "    for hit in res['hits'][:6]:\n",
    "        print(f'Doc {hit[\"_id\"]}, score is {hit[\"_score\"]}')\n",
    "        for field in fields:\n",
    "            print(f'{field}: {hit[\"_source\"][field]}')\n",
    "                  \n",
    "def get_doc_by_id(doc_id):\n",
    "    return es.get(index='myandex', id=doc_id)['_source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents: 10000\n",
      "Doc 658547, score is 1.073217\n",
      "Doc 1075085, score is 1.0685503\n",
      "Doc 571929, score is 1.0613596\n",
      "Doc 1412110, score is 1.0609068\n",
      "Doc 1132394, score is 1.0604091\n",
      "Doc 1128759, score is 1.0576842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('658547', 1.073217),\n",
       " ('1075085', 1.0685503),\n",
       " ('571929', 1.0613596),\n",
       " ('1412110', 1.0609068),\n",
       " ('1132394', 1.0604091),\n",
       " ('1128759', 1.0576842),\n",
       " ('816437', 1.0573583),\n",
       " ('1003757', 1.0573583),\n",
       " ('1170976', 1.0553992),\n",
       " ('1004958', 1.0553992),\n",
       " ('998704', 1.05511),\n",
       " ('1170977', 1.0550836),\n",
       " ('413190', 1.0531932),\n",
       " ('270685', 1.0531932),\n",
       " ('1227259', 1.0386738),\n",
       " ('825463', 1.0386703),\n",
       " ('826242', 1.0386703),\n",
       " ('649409', 1.0380677),\n",
       " ('363995', 1.0380677),\n",
       " ('90682', 1.0378789)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_query(query):\n",
    "    return {\n",
    "    'query': {\n",
    "        'bool': {\n",
    "            'must': {\n",
    "                'match': {\n",
    "                    'content': query\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    }\n",
    "\n",
    "q = get_query('<meta http-equiv=\"Content-Type\" content=\"text/html; charset=windows-1251\">')\n",
    "search(q)\n",
    "raw_search(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_index_size(index): \n",
    "    print(f\"Size of index: {es.indices.stats(index)['_all']['primaries']['store']['size_in_bytes'] / 2 ** 30} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of index: 4.730848075821996 GB\n"
     ]
    }
   ],
   "source": [
    "print_index_size('myandex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_queries_and_relevance():\n",
    "    relevance = defaultdict(dict)\n",
    "    filename = '../or_relevant-minus_table.xml'\n",
    "    with open(filename, 'rb') as f:\n",
    "        xmldict = xmltodict.parse(f.read())\n",
    "        for task in tqdm(xmldict['taskDocumentMatrix']['task']):\n",
    "            task_rel = {}\n",
    "            has_vital = False\n",
    "            for doc in task['document']:\n",
    "                if doc['@relevance'] == 'vital':\n",
    "                    has_vital = True\n",
    "                task_rel[doc['@id']] = doc['@relevance']\n",
    "            if has_vital:\n",
    "                relevance[task['@id']] = task_rel\n",
    "    filename = '../web2008_adhoc.xml'\n",
    "    with open(filename, 'rb') as f:\n",
    "        xmldict = xmltodict.parse(f.read())\n",
    "        for task in tqdm(xmldict['task-set']['task']):\n",
    "            if task['@id'] in relevance:\n",
    "                relevance[task['@id']]['querytext'] = task['querytext']\n",
    "    return relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daa4bc17f5bd4d2c86d4d4dfbb63e24b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=547), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36aadc18d46d480eb162425161c95b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=29231), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "relevance = load_queries_and_relevance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_of_correct_out_of_k(results, task_relevance, k):\n",
    "    return sum([1 if res[0] in task_relevance and task_relevance[res[0]] == 'vital' else 0 for res in results[:k]])\n",
    "\n",
    "def measure_performance():    \n",
    "    Q = len(relevance)\n",
    "    pq = 0\n",
    "    rq = 0\n",
    "    prq = 0\n",
    "    mapq = 0\n",
    "    for task in relevance.keys():\n",
    "        sk = 0\n",
    "        task_relevance = relevance[task]\n",
    "        results = raw_search(get_query(task_relevance['querytext']))\n",
    "        #if len(results) < 20:\n",
    "        #    print(\"WARNING LESS 20\")\n",
    "        sk = get_number_of_correct_out_of_k(results, task_relevance, 20)\n",
    "        pq += sk / 20\n",
    "        relevant_size = len(['vital' for value in task_relevance.values() if value == 'vital'])\n",
    "        rq += sk / relevant_size\n",
    "        prq += get_number_of_correct_out_of_k(results, task_relevance, relevant_size) / relevant_size\n",
    "        mapk = 0\n",
    "        for k in range(1, 21):\n",
    "            mapk += get_number_of_correct_out_of_k(results, task_relevance, k) / k\n",
    "        mapk /= 20\n",
    "        mapq += mapk\n",
    "    print(f\"p@20: {pq / Q}\")\n",
    "    print(f\"r@20: {rq / Q}\")\n",
    "    print(f\"p@R(q): {prq / Q}\")\n",
    "    print(f\"map@20(q): {mapq / Q}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p@20: 0.32030303030303003\n",
      "r@20: 0.21159064988861792\n",
      "p@R(q): 0.17777957736425143\n",
      "map@20(q): 0.3789026185277477\n"
     ]
    }
   ],
   "source": [
    "measure_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_homeworks)",
   "language": "python",
   "name": "ml_homeworks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
